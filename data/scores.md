

## Table S1. Multi-Evaluator Scores for All Models (Raw + Averaged)

| Model ↓ / Evaluator → | Claude-Sonnet-4.5 | Gemini-2.5-Flash-Lite | GPT-4.1 | Qwen-3-8B | DeepSeek-V3.2 | Gemini-2.5-Flash | Qwen3-8B-finetuned | GLM-4.6 |
|----------------------|-------------------|------------------------|---------|-----------|----------------|-------------------|---------------------|---------|
| DeepSeek-V3.2-Exp    | 90.73             | 88.25                  | 92.32   | 77.82     | 92.81          | 92.01             | 91.69               | 88.90   |
| GPT-4.1              | 92.05             | 88.38                  | 91.14   | 84.98     | 92.03          | 90.96             | 91.09               | 87.64   |
| Kimi-K2              | 92.02             | 86.06                  | 90.87   | 81.14     | 93.07          | 90.55             | 92.63               | 88.60   |
| Qwen3-Next-80B       | 61.72             | 62.68                  | 60.03   | 58.88     | 59.31          | 57.00             | 62.12               | 63.41   |
| **Sum**              | **336.52**        | **325.37**             | **334.35** | **302.82** | **337.22**     | **330.52**        | **337.53**          | **328.56** |
| **Average H-Score**  | **84.13**         | **81.34**              | **83.59** | **75.71** | **84.30**      | **82.63**         | **84.38**           | **82.14** |

The experimental evaluation employed a Chinese-language test dataset.
